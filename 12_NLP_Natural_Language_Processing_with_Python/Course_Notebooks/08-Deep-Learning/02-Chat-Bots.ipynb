{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)\n",
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first story\n",
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question\n",
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer\n",
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()\n",
    "all_data = test_data + train_data\n",
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 # we add an extra space to hold a 0 for Keras's pad_sequences\n",
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])\n",
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journeyed': 1,\n",
       " 'sandra': 2,\n",
       " 'office': 3,\n",
       " 'apple': 4,\n",
       " 'dropped': 5,\n",
       " 'daniel': 6,\n",
       " '.': 7,\n",
       " 'to': 8,\n",
       " 'mary': 9,\n",
       " 'john': 10,\n",
       " 'put': 11,\n",
       " 'hallway': 12,\n",
       " 'got': 13,\n",
       " 'went': 14,\n",
       " '?': 15,\n",
       " 'bathroom': 16,\n",
       " 'back': 17,\n",
       " 'up': 18,\n",
       " 'took': 19,\n",
       " 'kitchen': 20,\n",
       " 'is': 21,\n",
       " 'down': 22,\n",
       " 'milk': 23,\n",
       " 'yes': 24,\n",
       " 'grabbed': 25,\n",
       " 'there': 26,\n",
       " 'in': 27,\n",
       " 'left': 28,\n",
       " 'no': 29,\n",
       " 'picked': 30,\n",
       " 'bedroom': 31,\n",
       " 'discarded': 32,\n",
       " 'football': 33,\n",
       " 'garden': 34,\n",
       " 'the': 35,\n",
       " 'moved': 36,\n",
       " 'travelled': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answer_text.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len, max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT:     \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "    OUTPUT:    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    X = []        # X = STORIES\n",
    "    Xq = []       # Xq = QUERY/QUESTION\n",
    "    Y = []        # Y = CORRECT ANSWER\n",
    "    \n",
    "    for story, query, answer in data:    \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 35, 31,  7],\n",
       "       [ 0,  0,  0, ..., 35, 34,  7],\n",
       "       [ 0,  0,  0, ..., 35, 34,  7],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 35,  4,  7],\n",
       "       [ 0,  0,  0, ..., 35, 34,  7],\n",
       "       [ 0,  0,  0, ...,  4, 26,  7]], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 10, 27, 35, 20, 15],\n",
       "       [21, 10, 27, 35, 20, 15],\n",
       "       [21, 10, 27, 35, 34, 15],\n",
       "       ...,\n",
       "       [21,  9, 27, 35, 31, 15],\n",
       "       [21,  2, 27, 35, 34, 15],\n",
       "       [21,  9, 27, 35, 34, 15]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 497.,   0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/greg/miniconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #155: KMP_AFFINITY: Initial OS proc set respected: 0-11\n",
      "OMP: Info #217: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #157: KMP_AFFINITY: 12 available OS procs\n",
      "OMP: Info #158: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #288: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "OMP: Info #288: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "OMP: Info #288: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"core\".\n",
      "OMP: Info #288: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"core\".\n",
      "OMP: Info #192: KMP_AFFINITY: 1 socket x 6 cores/socket x 2 threads/core (6 total cores)\n",
      "OMP: Info #219: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 1 maps to socket 0 core 0 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 2 maps to socket 0 core 1 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 3 maps to socket 0 core 1 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 4 maps to socket 0 core 2 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 5 maps to socket 0 core 2 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 6 maps to socket 0 core 3 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 7 maps to socket 0 core 3 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 8 maps to socket 0 core 4 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 9 maps to socket 0 core 4 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 10 maps to socket 0 core 5 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 11 maps to socket 0 core 5 thread 1 \n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3712 thread 0 bound to OS proc set 0\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3728 thread 1 bound to OS proc set 2\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3730 thread 3 bound to OS proc set 6\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3731 thread 4 bound to OS proc set 8\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3729 thread 2 bound to OS proc set 4\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3732 thread 5 bound to OS proc set 10\n"
     ]
    }
   ],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/greg/miniconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/greg/miniconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 03:45:51.835978: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-08-22 03:45:51.889417: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592005000 Hz\n",
      "2022-08-22 03:45:51.890164: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d55bd52540 executing computations on platform Host. Devices:\n",
      "2022-08-22 03:45:51.890250: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2022-08-22 03:45:51.904026: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3740 thread 6 bound to OS proc set 1\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3765 thread 7 bound to OS proc set 3\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3766 thread 8 bound to OS proc set 5\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3767 thread 9 bound to OS proc set 7\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3768 thread 10 bound to OS proc set 9\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3769 thread 11 bound to OS proc set 11\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3770 thread 12 bound to OS proc set 0\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3739 thread 13 bound to OS proc set 2\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3772 thread 15 bound to OS proc set 6\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3773 thread 16 bound to OS proc set 8\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3771 thread 14 bound to OS proc set 4\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3774 thread 17 bound to OS proc set 10\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3775 thread 18 bound to OS proc set 1\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3777 thread 20 bound to OS proc set 5\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3776 thread 19 bound to OS proc set 3\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3778 thread 21 bound to OS proc set 7\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3779 thread 22 bound to OS proc set 9\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3780 thread 23 bound to OS proc set 11\n",
      "OMP: Info #255: KMP_AFFINITY: pid 3712 tid 3781 thread 24 bound to OS proc set 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.9796 - accuracy: 0.4922 - val_loss: 0.7010 - val_accuracy: 0.4970\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.7098 - accuracy: 0.4978 - val_loss: 0.6946 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6971 - accuracy: 0.5004 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6954 - accuracy: 0.4982 - val_loss: 0.6940 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6949 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 10s 960us/step - loss: 0.6940 - accuracy: 0.5065 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 10s 966us/step - loss: 0.6945 - accuracy: 0.4981 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 10s 992us/step - loss: 0.6950 - accuracy: 0.4955 - val_loss: 0.6935 - val_accuracy: 0.4790\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 9s 936us/step - loss: 0.6939 - accuracy: 0.5030 - val_loss: 0.6944 - val_accuracy: 0.4970\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6937 - accuracy: 0.5078 - val_loss: 0.6944 - val_accuracy: 0.4960\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6952 - val_accuracy: 0.4770\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6914 - accuracy: 0.5125 - val_loss: 0.7010 - val_accuracy: 0.4790\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6875 - accuracy: 0.5300 - val_loss: 0.6935 - val_accuracy: 0.5190\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 10s 995us/step - loss: 0.6768 - accuracy: 0.5628 - val_loss: 0.6745 - val_accuracy: 0.5570\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 10s 980us/step - loss: 0.6564 - accuracy: 0.6005 - val_loss: 0.6544 - val_accuracy: 0.6260\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 10s 962us/step - loss: 0.6388 - accuracy: 0.6370 - val_loss: 0.6324 - val_accuracy: 0.6620\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6123 - accuracy: 0.6721 - val_loss: 0.5994 - val_accuracy: 0.6820\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 10s 963us/step - loss: 0.5728 - accuracy: 0.7199 - val_loss: 0.5600 - val_accuracy: 0.7040\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 10s 954us/step - loss: 0.5557 - accuracy: 0.7304 - val_loss: 0.5357 - val_accuracy: 0.7450\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.5274 - accuracy: 0.7493 - val_loss: 0.5040 - val_accuracy: 0.7670\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.5169 - accuracy: 0.7572 - val_loss: 0.4918 - val_accuracy: 0.7840\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.5031 - accuracy: 0.7678 - val_loss: 0.4944 - val_accuracy: 0.7860\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4911 - accuracy: 0.7753 - val_loss: 0.4764 - val_accuracy: 0.7900\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4837 - accuracy: 0.7747 - val_loss: 0.4822 - val_accuracy: 0.7810\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 10s 996us/step - loss: 0.4700 - accuracy: 0.7901 - val_loss: 0.4561 - val_accuracy: 0.7990\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 10s 962us/step - loss: 0.4681 - accuracy: 0.7906 - val_loss: 0.4516 - val_accuracy: 0.8030\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 10s 951us/step - loss: 0.4499 - accuracy: 0.8013 - val_loss: 0.4452 - val_accuracy: 0.8020\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 10s 952us/step - loss: 0.4379 - accuracy: 0.8056 - val_loss: 0.4260 - val_accuracy: 0.8130\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 10s 968us/step - loss: 0.4179 - accuracy: 0.8166 - val_loss: 0.4509 - val_accuracy: 0.8050\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4205 - accuracy: 0.8206 - val_loss: 0.4326 - val_accuracy: 0.8170\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.4110 - accuracy: 0.8224 - val_loss: 0.4199 - val_accuracy: 0.8010\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.4012 - accuracy: 0.8312 - val_loss: 0.4146 - val_accuracy: 0.8220\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3878 - accuracy: 0.8370 - val_loss: 0.4355 - val_accuracy: 0.7950\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3858 - accuracy: 0.8369 - val_loss: 0.4218 - val_accuracy: 0.8120\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3842 - accuracy: 0.8380 - val_loss: 0.4229 - val_accuracy: 0.8210\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3862 - accuracy: 0.8392 - val_loss: 0.4192 - val_accuracy: 0.8170\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3738 - accuracy: 0.8420 - val_loss: 0.3973 - val_accuracy: 0.8180\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3703 - accuracy: 0.8429 - val_loss: 0.4034 - val_accuracy: 0.8170\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.3699 - accuracy: 0.8415 - val_loss: 0.4061 - val_accuracy: 0.8230\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3674 - accuracy: 0.8444 - val_loss: 0.4070 - val_accuracy: 0.8280\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3571 - accuracy: 0.8516 - val_loss: 0.3927 - val_accuracy: 0.8300\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3613 - accuracy: 0.8513 - val_loss: 0.3940 - val_accuracy: 0.8220\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3558 - accuracy: 0.8508 - val_loss: 0.4045 - val_accuracy: 0.8260\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 10s 977us/step - loss: 0.3539 - accuracy: 0.8514 - val_loss: 0.4195 - val_accuracy: 0.8190\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 9s 945us/step - loss: 0.3484 - accuracy: 0.8525 - val_loss: 0.3988 - val_accuracy: 0.8130\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 10s 988us/step - loss: 0.3458 - accuracy: 0.8547 - val_loss: 0.3987 - val_accuracy: 0.8230\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 10s 980us/step - loss: 0.3410 - accuracy: 0.8586 - val_loss: 0.4056 - val_accuracy: 0.8230\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 10s 956us/step - loss: 0.3437 - accuracy: 0.8535 - val_loss: 0.3947 - val_accuracy: 0.8210\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 10s 967us/step - loss: 0.3316 - accuracy: 0.8608 - val_loss: 0.4216 - val_accuracy: 0.8160\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3346 - accuracy: 0.8587 - val_loss: 0.4063 - val_accuracy: 0.8280\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 10s 981us/step - loss: 0.3261 - accuracy: 0.8605 - val_loss: 0.4100 - val_accuracy: 0.8200\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 10s 967us/step - loss: 0.3322 - accuracy: 0.8605 - val_loss: 0.4146 - val_accuracy: 0.8140\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3319 - accuracy: 0.8622 - val_loss: 0.3853 - val_accuracy: 0.8280\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 9s 944us/step - loss: 0.3224 - accuracy: 0.8633 - val_loss: 0.3997 - val_accuracy: 0.8210\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 10s 961us/step - loss: 0.3252 - accuracy: 0.8636 - val_loss: 0.3906 - val_accuracy: 0.8230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 10s 968us/step - loss: 0.3189 - accuracy: 0.8630 - val_loss: 0.4154 - val_accuracy: 0.8180\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 10s 958us/step - loss: 0.3197 - accuracy: 0.8637 - val_loss: 0.3976 - val_accuracy: 0.8160\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 10s 954us/step - loss: 0.3141 - accuracy: 0.8697 - val_loss: 0.4016 - val_accuracy: 0.8200\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3121 - accuracy: 0.8698 - val_loss: 0.4398 - val_accuracy: 0.8130\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3100 - accuracy: 0.8686 - val_loss: 0.4230 - val_accuracy: 0.8130\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3138 - accuracy: 0.8676 - val_loss: 0.3985 - val_accuracy: 0.8230\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 10s 982us/step - loss: 0.3082 - accuracy: 0.8718 - val_loss: 0.4197 - val_accuracy: 0.8090\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 10s 963us/step - loss: 0.3010 - accuracy: 0.8737 - val_loss: 0.4164 - val_accuracy: 0.8110\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3024 - accuracy: 0.8729 - val_loss: 0.4323 - val_accuracy: 0.8140\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3030 - accuracy: 0.8724 - val_loss: 0.4314 - val_accuracy: 0.8070\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3028 - accuracy: 0.8717 - val_loss: 0.4091 - val_accuracy: 0.8210\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 10s 999us/step - loss: 0.2970 - accuracy: 0.8748 - val_loss: 0.4424 - val_accuracy: 0.8160\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2924 - accuracy: 0.8795 - val_loss: 0.4374 - val_accuracy: 0.8090\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2916 - accuracy: 0.8767 - val_loss: 0.4501 - val_accuracy: 0.8070\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2814 - accuracy: 0.8813 - val_loss: 0.4264 - val_accuracy: 0.8120\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2892 - accuracy: 0.8784 - val_loss: 0.4347 - val_accuracy: 0.8140\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2890 - accuracy: 0.8771 - val_loss: 0.4332 - val_accuracy: 0.8220\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2789 - accuracy: 0.8839 - val_loss: 0.4506 - val_accuracy: 0.8050\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 10s 967us/step - loss: 0.2808 - accuracy: 0.8820 - val_loss: 0.4356 - val_accuracy: 0.8170\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 10s 975us/step - loss: 0.2827 - accuracy: 0.8836 - val_loss: 0.4160 - val_accuracy: 0.8140\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 10s 994us/step - loss: 0.2787 - accuracy: 0.8854 - val_loss: 0.4349 - val_accuracy: 0.8150\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 10s 961us/step - loss: 0.2826 - accuracy: 0.8833 - val_loss: 0.4364 - val_accuracy: 0.8130\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 10s 964us/step - loss: 0.2792 - accuracy: 0.8822 - val_loss: 0.4379 - val_accuracy: 0.8120\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2768 - accuracy: 0.8841 - val_loss: 0.4161 - val_accuracy: 0.8180\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 10s 963us/step - loss: 0.2729 - accuracy: 0.8891 - val_loss: 0.4508 - val_accuracy: 0.8160\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 10s 981us/step - loss: 0.2709 - accuracy: 0.8856 - val_loss: 0.4445 - val_accuracy: 0.8210\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 10s 986us/step - loss: 0.2644 - accuracy: 0.8888 - val_loss: 0.4498 - val_accuracy: 0.8100\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2633 - accuracy: 0.8911 - val_loss: 0.4464 - val_accuracy: 0.8150\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2728 - accuracy: 0.8893 - val_loss: 0.4564 - val_accuracy: 0.8110\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2666 - accuracy: 0.8882 - val_loss: 0.4590 - val_accuracy: 0.8120\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2613 - accuracy: 0.8910 - val_loss: 0.4611 - val_accuracy: 0.8080\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 10s 993us/step - loss: 0.2641 - accuracy: 0.8906 - val_loss: 0.4835 - val_accuracy: 0.8150\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2554 - accuracy: 0.8953 - val_loss: 0.4707 - val_accuracy: 0.8140\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2524 - accuracy: 0.8946 - val_loss: 0.4762 - val_accuracy: 0.8170\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 10s 993us/step - loss: 0.2493 - accuracy: 0.8972 - val_loss: 0.5232 - val_accuracy: 0.8020\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2554 - accuracy: 0.8916 - val_loss: 0.4720 - val_accuracy: 0.8170\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 9s 944us/step - loss: 0.2616 - accuracy: 0.8905 - val_loss: 0.4816 - val_accuracy: 0.8100\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 9s 929us/step - loss: 0.2525 - accuracy: 0.8956 - val_loss: 0.4604 - val_accuracy: 0.8090\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 10s 988us/step - loss: 0.2494 - accuracy: 0.8993 - val_loss: 0.4975 - val_accuracy: 0.8120\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2528 - accuracy: 0.8922 - val_loss: 0.4891 - val_accuracy: 0.8080\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 10s 970us/step - loss: 0.2463 - accuracy: 0.8999 - val_loss: 0.4836 - val_accuracy: 0.8160\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2422 - accuracy: 0.8992 - val_loss: 0.4877 - val_accuracy: 0.8070\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 9s 940us/step - loss: 0.2452 - accuracy: 0.9007 - val_loss: 0.5079 - val_accuracy: 0.8100\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 10s 962us/step - loss: 0.2423 - accuracy: 0.9005 - val_loss: 0.5154 - val_accuracy: 0.8040\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 10s 999us/step - loss: 0.2460 - accuracy: 0.8984 - val_loss: 0.5059 - val_accuracy: 0.8080\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 10s 951us/step - loss: 0.2436 - accuracy: 0.8989 - val_loss: 0.5112 - val_accuracy: 0.8170\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 10s 977us/step - loss: 0.2407 - accuracy: 0.8999 - val_loss: 0.5274 - val_accuracy: 0.8080\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 10s 958us/step - loss: 0.2380 - accuracy: 0.9011 - val_loss: 0.5098 - val_accuracy: 0.8090\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 9s 950us/step - loss: 0.2355 - accuracy: 0.9032 - val_loss: 0.5301 - val_accuracy: 0.8070\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 10s 959us/step - loss: 0.2338 - accuracy: 0.9089 - val_loss: 0.5541 - val_accuracy: 0.8010\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2354 - accuracy: 0.9052 - val_loss: 0.5811 - val_accuracy: 0.8000\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 10s 958us/step - loss: 0.2331 - accuracy: 0.9050 - val_loss: 0.5330 - val_accuracy: 0.8060\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 9s 950us/step - loss: 0.2306 - accuracy: 0.9096 - val_loss: 0.5654 - val_accuracy: 0.8040\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 10s 966us/step - loss: 0.2325 - accuracy: 0.9078 - val_loss: 0.5345 - val_accuracy: 0.8040\n",
      "Epoch 110/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 961us/step - loss: 0.2317 - accuracy: 0.9046 - val_loss: 0.5787 - val_accuracy: 0.7910\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 10s 958us/step - loss: 0.2264 - accuracy: 0.9071 - val_loss: 0.5680 - val_accuracy: 0.7880\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2295 - accuracy: 0.9067 - val_loss: 0.5203 - val_accuracy: 0.8030\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 10s 961us/step - loss: 0.2254 - accuracy: 0.9097 - val_loss: 0.5978 - val_accuracy: 0.8010\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2324 - accuracy: 0.9045 - val_loss: 0.5540 - val_accuracy: 0.7980\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2209 - accuracy: 0.9095 - val_loss: 0.6022 - val_accuracy: 0.8100\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 9s 936us/step - loss: 0.2229 - accuracy: 0.9108 - val_loss: 0.5739 - val_accuracy: 0.8040\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 9s 949us/step - loss: 0.2188 - accuracy: 0.9093 - val_loss: 0.5966 - val_accuracy: 0.7980\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 9s 949us/step - loss: 0.2180 - accuracy: 0.9100 - val_loss: 0.5742 - val_accuracy: 0.8030\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 10s 984us/step - loss: 0.2219 - accuracy: 0.9089 - val_loss: 0.5680 - val_accuracy: 0.8080\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2181 - accuracy: 0.9082 - val_loss: 0.5677 - val_accuracy: 0.7990\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3712/330948904.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
